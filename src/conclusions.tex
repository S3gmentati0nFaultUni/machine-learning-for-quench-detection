\chapter{Conclusions}
\label{chp:conclusion}
In this thesis we have proposed a solution to the problem of identifying quench events and
localizing them within the magnet structure using the harmonic decomposition of magnetic field. We
have provided a very strong solution for the first, and we have provided a good starting point for
the second. During the project, we had different ideas to branch out and further explore the
fascinating realm of machine learning applied to superconductor physics.

We remark that, while the analysis we have done has been thorough, the performance achieved and the
identified models only work on the specific case of the High order corrector quadrupolar magnets.
We have serious doubts that this analysis could be extended to any other quadrupole; and extending it to magnets with a different number of poles would yield unusable results.

To achieve higher performance on \dts\ for \qlp, we can do further analysis on the models we
identified so far; or we can opt for a more powerful model and opt for \emph{post-hoc}
explainability~\cite{retzlaff2024}. While in the first case it's only a matter of experimentation,
in the second case we would need more data, but the result of such an analysis wouldn't necessarily
yield highly explainable results.

\subsubsection{Analysis of the decision rules and general detection model}
In the project we have identified highly explainable models, capable of solving \qrp\ and \qlp\
maintaining high performance. The obvious next step, is to open the models and abstract
useful rules, capable of explaining quench and localizing events in certain coils. These rules could
be used:
\begin{itemize}
	\item In the field of sensor calibration, to isolate the harmonics that we truly need; simplifying sensor design, while also making the Quench Protection System more efficient,
	\item Support in the magnet design process.
\end{itemize}

\subsubsection{Fuzzification of quench-event description}
For both our problems the quench-event was described by a binary value, if $0$ then the sample
remained in the superconducting state, if $1$, then the material transitioned to the
normal-conducting state. An interesting option would be to change the description of quenches,
moving to a representation of the label as a real number in the interval $[0, 1]$.

By moving to this new description we could leverage a higher expressivity, highlighting different
behaviors: characterizing the rapidity of a transition to the normal-conducting state, or measuring
the violence of the quench transition (how high is the spike of resistive voltage for the quench
precursor). The ones above are just examples, we could use this new labelling system do explain
different aspects of the magnet. The different descriptions would have to be inspected by a
Physicist to understand which correlation is more interesting to investigate.

\subsubsection{Analysis of Voltage data}
In the original experiment two different measures were taken on the magnets: magnetic measures (the
ones we used throughout this thesis) and voltage taps. Voltage taps are used to measure the voltage
in different positions inside the magnet, these taps are then connected to the electronics of the
\textsc{qps}.

The magnetic measurement system is much slower compared to the voltage measurement system; this
means that we have much more data at our disposal that has not yet been used. At the time of writing
we are starting a cooperation with Naples University to build high-performance models on such data.

\subsubsection{High performance quench localization}
High-performance models for online quench detection and localization, are a different area of
research (quite active at the moment~\cite{hoang2021, zhou2021, einstein2023}).

Many are the alternatives: the \svcs\ explored in this thesis, neural networks or anomaly detection
via autoencoders. Clearly, pursuing such path forces us to invalid the explainability property we
granted throughout the project, unless explainable-ai models were used.

\subsubsection{Clustering-based preprocessing for classification}
Another technique that could be worth exploring is Clustering. We saw in the last chapter how the
points were very nicely distributed in bidimensional space, specifically for attribute \an, but also
for attribute \cnmod.

As we said in \Cref{sec:qlp-cluster} we could likely use clustering as a preprocessing step and then
extrapolate the results using highly explainable models like \dts\ and \rfs. We could also do a
first run of $k$-means clustering and then finalize classification using $k$-nn. Both approaches
would be extremely viable, at the expense, once more, of explainability (since we use $k$-means and
\pca, which are inherently non-explainable).




